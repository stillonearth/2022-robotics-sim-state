{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "c:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\stable_baselines3\\common\\cmd_util.py:5: FutureWarning: Module ``common.cmd_util`` has been renamed to ``common.env_util`` and will be removed in the future.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from environments import *\n",
    "\n",
    "from stable_baselines3 import HerReplayBuffer, SAC, DDPG, TD3\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.cmd_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\core.py:329: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = make_vec_env(\"G1Dist-v0\", 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "model = SAC(\n",
    "    \"MlpPolicy\", \n",
    "    env, \n",
    "    verbose=1,\n",
    "    policy_kwargs=dict(net_arch=[512, 512, 512, 512]),\n",
    "    batch_size=512,\n",
    ")\n",
    "model.load('g1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 99.2      |\n",
      "|    ep_rew_mean     | -1.34e+05 |\n",
      "| time/              |           |\n",
      "|    episodes        | 1000      |\n",
      "|    fps             | 722       |\n",
      "|    time_elapsed    | 216       |\n",
      "|    total_timesteps | 156352    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.64e+04  |\n",
      "|    critic_loss     | 9.22e+06  |\n",
      "|    ent_coef        | 2.76      |\n",
      "|    ent_coef_loss   | -4.22     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 4882      |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 116      |\n",
      "|    ep_rew_mean     | -1.1e+05 |\n",
      "| time/              |          |\n",
      "|    episodes        | 2000     |\n",
      "|    fps             | 729      |\n",
      "|    time_elapsed    | 356      |\n",
      "|    total_timesteps | 260160   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 5.28e+04 |\n",
      "|    critic_loss     | 1.48e+07 |\n",
      "|    ent_coef        | 5.52     |\n",
      "|    ent_coef_loss   | -2.65    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 8126     |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 122       |\n",
      "|    ep_rew_mean     | -8.42e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 3000      |\n",
      "|    fps             | 735       |\n",
      "|    time_elapsed    | 486       |\n",
      "|    total_timesteps | 357952    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.1e+04   |\n",
      "|    critic_loss     | 9.54e+06  |\n",
      "|    ent_coef        | 8.08      |\n",
      "|    ent_coef_loss   | -0.568    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 11182     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 69.3      |\n",
      "|    ep_rew_mean     | -5.73e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 4000      |\n",
      "|    fps             | 741       |\n",
      "|    time_elapsed    | 582       |\n",
      "|    total_timesteps | 431840    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.85e+04  |\n",
      "|    critic_loss     | 1.31e+07  |\n",
      "|    ent_coef        | 9.13      |\n",
      "|    ent_coef_loss   | 0.66      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 13491     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 59.7     |\n",
      "|    ep_rew_mean     | -4e+04   |\n",
      "| time/              |          |\n",
      "|    episodes        | 5000     |\n",
      "|    fps             | 744      |\n",
      "|    time_elapsed    | 669      |\n",
      "|    total_timesteps | 498208   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 4.43e+04 |\n",
      "|    critic_loss     | 1.13e+07 |\n",
      "|    ent_coef        | 9.98     |\n",
      "|    ent_coef_loss   | 0.502    |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 15565    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 55.8      |\n",
      "|    ep_rew_mean     | -3.17e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 6000      |\n",
      "|    fps             | 748       |\n",
      "|    time_elapsed    | 747       |\n",
      "|    total_timesteps | 559136    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.23e+04  |\n",
      "|    critic_loss     | 1.29e+07  |\n",
      "|    ent_coef        | 10.7      |\n",
      "|    ent_coef_loss   | -0.535    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 17469     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 56.6      |\n",
      "|    ep_rew_mean     | -2.68e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 7000      |\n",
      "|    fps             | 749       |\n",
      "|    time_elapsed    | 823       |\n",
      "|    total_timesteps | 617216    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.73e+04  |\n",
      "|    critic_loss     | 1.16e+07  |\n",
      "|    ent_coef        | 11.3      |\n",
      "|    ent_coef_loss   | -0.957    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 19284     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 53.5      |\n",
      "|    ep_rew_mean     | -2.44e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 8000      |\n",
      "|    fps             | 751       |\n",
      "|    time_elapsed    | 894       |\n",
      "|    total_timesteps | 672288    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.53e+04  |\n",
      "|    critic_loss     | 1.05e+07  |\n",
      "|    ent_coef        | 11.6      |\n",
      "|    ent_coef_loss   | -0.133    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 21005     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 49.1      |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 9000      |\n",
      "|    fps             | 752       |\n",
      "|    time_elapsed    | 964       |\n",
      "|    total_timesteps | 725312    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.14e+04  |\n",
      "|    critic_loss     | 4.88e+06  |\n",
      "|    ent_coef        | 11.8      |\n",
      "|    ent_coef_loss   | 0.378     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 22662     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 53.7     |\n",
      "|    ep_rew_mean     | -2.2e+04 |\n",
      "| time/              |          |\n",
      "|    episodes        | 10000    |\n",
      "|    fps             | 752      |\n",
      "|    time_elapsed    | 1034     |\n",
      "|    total_timesteps | 778496   |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 2.94e+04 |\n",
      "|    critic_loss     | 6.16e+06 |\n",
      "|    ent_coef        | 12       |\n",
      "|    ent_coef_loss   | 1.23     |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 24324    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 53.5      |\n",
      "|    ep_rew_mean     | -2.08e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 11000     |\n",
      "|    fps             | 751       |\n",
      "|    time_elapsed    | 1104      |\n",
      "|    total_timesteps | 830752    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.69e+04  |\n",
      "|    critic_loss     | 7.51e+06  |\n",
      "|    ent_coef        | 12        |\n",
      "|    ent_coef_loss   | -0.603    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 25957     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 51.2      |\n",
      "|    ep_rew_mean     | -2.08e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 12000     |\n",
      "|    fps             | 753       |\n",
      "|    time_elapsed    | 1172      |\n",
      "|    total_timesteps | 882816    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.46e+04  |\n",
      "|    critic_loss     | 5.38e+06  |\n",
      "|    ent_coef        | 11.9      |\n",
      "|    ent_coef_loss   | -0.146    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 27584     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48.8      |\n",
      "|    ep_rew_mean     | -1.62e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 13000     |\n",
      "|    fps             | 754       |\n",
      "|    time_elapsed    | 1237      |\n",
      "|    total_timesteps | 934240    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.28e+04  |\n",
      "|    critic_loss     | 3.98e+06  |\n",
      "|    ent_coef        | 11.6      |\n",
      "|    ent_coef_loss   | -0.174    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 29191     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 49.6      |\n",
      "|    ep_rew_mean     | -1.84e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 14000     |\n",
      "|    fps             | 756       |\n",
      "|    time_elapsed    | 1303      |\n",
      "|    total_timesteps | 985600    |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 2.18e+04  |\n",
      "|    critic_loss     | 1.97e+06  |\n",
      "|    ent_coef        | 11.3      |\n",
      "|    ent_coef_loss   | -0.0655   |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 30796     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48.4      |\n",
      "|    ep_rew_mean     | -1.64e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 15000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1368      |\n",
      "|    total_timesteps | 1036384   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.88e+04  |\n",
      "|    critic_loss     | 2.41e+06  |\n",
      "|    ent_coef        | 10.9      |\n",
      "|    ent_coef_loss   | -0.584    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 32383     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 50.4      |\n",
      "|    ep_rew_mean     | -1.55e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 16000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1435      |\n",
      "|    total_timesteps | 1087840   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.69e+04  |\n",
      "|    critic_loss     | 1.57e+06  |\n",
      "|    ent_coef        | 10.4      |\n",
      "|    ent_coef_loss   | 0.0588    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 33991     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 52        |\n",
      "|    ep_rew_mean     | -1.48e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 17000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1502      |\n",
      "|    total_timesteps | 1138624   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.45e+04  |\n",
      "|    critic_loss     | 7.77e+05  |\n",
      "|    ent_coef        | 9.96      |\n",
      "|    ent_coef_loss   | 1.91      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 35578     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 45.1      |\n",
      "|    ep_rew_mean     | -1.18e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 18000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1569      |\n",
      "|    total_timesteps | 1188928   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.35e+04  |\n",
      "|    critic_loss     | 2.36e+06  |\n",
      "|    ent_coef        | 9.28      |\n",
      "|    ent_coef_loss   | -0.177    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 37150     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 49.4      |\n",
      "|    ep_rew_mean     | -1.19e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 19000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1634      |\n",
      "|    total_timesteps | 1237728   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.23e+04  |\n",
      "|    critic_loss     | 3.91e+05  |\n",
      "|    ent_coef        | 8.78      |\n",
      "|    ent_coef_loss   | -0.374    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 38675     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 49        |\n",
      "|    ep_rew_mean     | -1.02e+04 |\n",
      "| time/              |           |\n",
      "|    episodes        | 20000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1698      |\n",
      "|    total_timesteps | 1286720   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 1.1e+04   |\n",
      "|    critic_loss     | 3.7e+05   |\n",
      "|    ent_coef        | 8.26      |\n",
      "|    ent_coef_loss   | 0.136     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 40206     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 45.7      |\n",
      "|    ep_rew_mean     | -9.18e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 21000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1762      |\n",
      "|    total_timesteps | 1335648   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 9.36e+03  |\n",
      "|    critic_loss     | 2.26e+05  |\n",
      "|    ent_coef        | 7.78      |\n",
      "|    ent_coef_loss   | -0.715    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 41735     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 47.8      |\n",
      "|    ep_rew_mean     | -8.74e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 22000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1827      |\n",
      "|    total_timesteps | 1384864   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 8.88e+03  |\n",
      "|    critic_loss     | 2.31e+05  |\n",
      "|    ent_coef        | 7.46      |\n",
      "|    ent_coef_loss   | -0.755    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 43273     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 45.5      |\n",
      "|    ep_rew_mean     | -7.88e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 23000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1893      |\n",
      "|    total_timesteps | 1433568   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 8.45e+03  |\n",
      "|    critic_loss     | 1.38e+05  |\n",
      "|    ent_coef        | 7.45      |\n",
      "|    ent_coef_loss   | -0.249    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 44795     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 49.1      |\n",
      "|    ep_rew_mean     | -8.64e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 24000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 1956      |\n",
      "|    total_timesteps | 1481824   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 7.73e+03  |\n",
      "|    critic_loss     | 1.93e+05  |\n",
      "|    ent_coef        | 7.56      |\n",
      "|    ent_coef_loss   | 0.476     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 46303     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48.1      |\n",
      "|    ep_rew_mean     | -7.21e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 25000     |\n",
      "|    fps             | 757       |\n",
      "|    time_elapsed    | 2018      |\n",
      "|    total_timesteps | 1529888   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 7.42e+03  |\n",
      "|    critic_loss     | 1.01e+05  |\n",
      "|    ent_coef        | 7.75      |\n",
      "|    ent_coef_loss   | 0.171     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 47805     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 51.9      |\n",
      "|    ep_rew_mean     | -7.67e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 26000     |\n",
      "|    fps             | 758       |\n",
      "|    time_elapsed    | 2083      |\n",
      "|    total_timesteps | 1579008   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 7.28e+03  |\n",
      "|    critic_loss     | 1.96e+05  |\n",
      "|    ent_coef        | 7.92      |\n",
      "|    ent_coef_loss   | -0.663    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 49340     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 48.7     |\n",
      "|    ep_rew_mean     | -6.4e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 27000    |\n",
      "|    fps             | 757      |\n",
      "|    time_elapsed    | 2147     |\n",
      "|    total_timesteps | 1627232  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.96e+03 |\n",
      "|    critic_loss     | 1.24e+05 |\n",
      "|    ent_coef        | 8.08     |\n",
      "|    ent_coef_loss   | -0.623   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 50847    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 52.2      |\n",
      "|    ep_rew_mean     | -6.77e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 28000     |\n",
      "|    fps             | 756       |\n",
      "|    time_elapsed    | 2214      |\n",
      "|    total_timesteps | 1675264   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 6.85e+03  |\n",
      "|    critic_loss     | 1.04e+05  |\n",
      "|    ent_coef        | 8.26      |\n",
      "|    ent_coef_loss   | -0.24     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 52348     |\n",
      "----------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.4     |\n",
      "|    ep_rew_mean     | -6.3e+03 |\n",
      "| time/              |          |\n",
      "|    episodes        | 29000    |\n",
      "|    fps             | 754      |\n",
      "|    time_elapsed    | 2284     |\n",
      "|    total_timesteps | 1724672  |\n",
      "| train/             |          |\n",
      "|    actor_loss      | 6.52e+03 |\n",
      "|    critic_loss     | 7.54e+04 |\n",
      "|    ent_coef        | 8.41     |\n",
      "|    ent_coef_loss   | -0.461   |\n",
      "|    learning_rate   | 0.0003   |\n",
      "|    n_updates       | 53892    |\n",
      "---------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 49.5      |\n",
      "|    ep_rew_mean     | -5.78e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 30000     |\n",
      "|    fps             | 752       |\n",
      "|    time_elapsed    | 2357      |\n",
      "|    total_timesteps | 1774208   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 6.77e+03  |\n",
      "|    critic_loss     | 1.02e+05  |\n",
      "|    ent_coef        | 8.54      |\n",
      "|    ent_coef_loss   | -0.0676   |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 55440     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48        |\n",
      "|    ep_rew_mean     | -5.07e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 31000     |\n",
      "|    fps             | 750       |\n",
      "|    time_elapsed    | 2427      |\n",
      "|    total_timesteps | 1822336   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.94e+03  |\n",
      "|    critic_loss     | 5.93e+04  |\n",
      "|    ent_coef        | 8.72      |\n",
      "|    ent_coef_loss   | -0.0351   |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 56944     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 47.2      |\n",
      "|    ep_rew_mean     | -4.79e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 32000     |\n",
      "|    fps             | 750       |\n",
      "|    time_elapsed    | 2492      |\n",
      "|    total_timesteps | 1869440   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 6.03e+03  |\n",
      "|    critic_loss     | 1.19e+05  |\n",
      "|    ent_coef        | 8.79      |\n",
      "|    ent_coef_loss   | -0.416    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 58416     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 50.6      |\n",
      "|    ep_rew_mean     | -5.22e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 33000     |\n",
      "|    fps             | 749       |\n",
      "|    time_elapsed    | 2558      |\n",
      "|    total_timesteps | 1916640   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 6.1e+03   |\n",
      "|    critic_loss     | 6.39e+04  |\n",
      "|    ent_coef        | 8.83      |\n",
      "|    ent_coef_loss   | 0.13      |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 59891     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 45.7      |\n",
      "|    ep_rew_mean     | -4.59e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 34000     |\n",
      "|    fps             | 748       |\n",
      "|    time_elapsed    | 2621      |\n",
      "|    total_timesteps | 1963680   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.92e+03  |\n",
      "|    critic_loss     | 5.13e+04  |\n",
      "|    ent_coef        | 8.9       |\n",
      "|    ent_coef_loss   | -0.824    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 61361     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 47.7      |\n",
      "|    ep_rew_mean     | -4.84e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 35000     |\n",
      "|    fps             | 748       |\n",
      "|    time_elapsed    | 2684      |\n",
      "|    total_timesteps | 2010208   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.7e+03   |\n",
      "|    critic_loss     | 4.29e+04  |\n",
      "|    ent_coef        | 8.93      |\n",
      "|    ent_coef_loss   | -0.32     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 62815     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 47.5      |\n",
      "|    ep_rew_mean     | -4.51e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 36000     |\n",
      "|    fps             | 748       |\n",
      "|    time_elapsed    | 2751      |\n",
      "|    total_timesteps | 2058464   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.4e+03   |\n",
      "|    critic_loss     | 2.98e+04  |\n",
      "|    ent_coef        | 8.92      |\n",
      "|    ent_coef_loss   | 0.242     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 64323     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 49.9      |\n",
      "|    ep_rew_mean     | -4.77e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 37000     |\n",
      "|    fps             | 747       |\n",
      "|    time_elapsed    | 2815      |\n",
      "|    total_timesteps | 2106080   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.58e+03  |\n",
      "|    critic_loss     | 5.42e+04  |\n",
      "|    ent_coef        | 9         |\n",
      "|    ent_coef_loss   | -0.185    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 65811     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 50.6      |\n",
      "|    ep_rew_mean     | -5.81e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 38000     |\n",
      "|    fps             | 747       |\n",
      "|    time_elapsed    | 2880      |\n",
      "|    total_timesteps | 2153984   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.14e+03  |\n",
      "|    critic_loss     | 4.14e+04  |\n",
      "|    ent_coef        | 9.05      |\n",
      "|    ent_coef_loss   | -0.0991   |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 67308     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 50.5      |\n",
      "|    ep_rew_mean     | -4.58e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 39000     |\n",
      "|    fps             | 747       |\n",
      "|    time_elapsed    | 2944      |\n",
      "|    total_timesteps | 2201024   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.34e+03  |\n",
      "|    critic_loss     | 3.83e+04  |\n",
      "|    ent_coef        | 8.98      |\n",
      "|    ent_coef_loss   | 0.0638    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 68778     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48.2      |\n",
      "|    ep_rew_mean     | -4.18e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 40000     |\n",
      "|    fps             | 747       |\n",
      "|    time_elapsed    | 3008      |\n",
      "|    total_timesteps | 2247616   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.25e+03  |\n",
      "|    critic_loss     | 2.52e+04  |\n",
      "|    ent_coef        | 8.94      |\n",
      "|    ent_coef_loss   | -0.159    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 70234     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 44.9      |\n",
      "|    ep_rew_mean     | -3.83e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 41000     |\n",
      "|    fps             | 747       |\n",
      "|    time_elapsed    | 3070      |\n",
      "|    total_timesteps | 2294688   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.15e+03  |\n",
      "|    critic_loss     | 2.68e+04  |\n",
      "|    ent_coef        | 8.94      |\n",
      "|    ent_coef_loss   | -0.249    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 71705     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.2      |\n",
      "|    ep_rew_mean     | -3.93e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 42000     |\n",
      "|    fps             | 747       |\n",
      "|    time_elapsed    | 3134      |\n",
      "|    total_timesteps | 2341920   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.77e+03  |\n",
      "|    critic_loss     | 2.04e+04  |\n",
      "|    ent_coef        | 8.91      |\n",
      "|    ent_coef_loss   | 0.0917    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 73181     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.8      |\n",
      "|    ep_rew_mean     | -4.11e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 43000     |\n",
      "|    fps             | 746       |\n",
      "|    time_elapsed    | 3197      |\n",
      "|    total_timesteps | 2388128   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 5.03e+03  |\n",
      "|    critic_loss     | 1.88e+04  |\n",
      "|    ent_coef        | 8.85      |\n",
      "|    ent_coef_loss   | 0.146     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 74625     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 45.2      |\n",
      "|    ep_rew_mean     | -3.62e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 44000     |\n",
      "|    fps             | 746       |\n",
      "|    time_elapsed    | 3261      |\n",
      "|    total_timesteps | 2435264   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.86e+03  |\n",
      "|    critic_loss     | 2.17e+04  |\n",
      "|    ent_coef        | 8.86      |\n",
      "|    ent_coef_loss   | -0.257    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 76098     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 44        |\n",
      "|    ep_rew_mean     | -3.46e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 45000     |\n",
      "|    fps             | 746       |\n",
      "|    time_elapsed    | 3325      |\n",
      "|    total_timesteps | 2481824   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.69e+03  |\n",
      "|    critic_loss     | 2.47e+04  |\n",
      "|    ent_coef        | 8.83      |\n",
      "|    ent_coef_loss   | -0.652    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 77553     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.8      |\n",
      "|    ep_rew_mean     | -3.77e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 46000     |\n",
      "|    fps             | 746       |\n",
      "|    time_elapsed    | 3389      |\n",
      "|    total_timesteps | 2529088   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.63e+03  |\n",
      "|    critic_loss     | 1.33e+04  |\n",
      "|    ent_coef        | 8.8       |\n",
      "|    ent_coef_loss   | 0.434     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 79030     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 45.9      |\n",
      "|    ep_rew_mean     | -3.57e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 47000     |\n",
      "|    fps             | 745       |\n",
      "|    time_elapsed    | 3456      |\n",
      "|    total_timesteps | 2576192   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.44e+03  |\n",
      "|    critic_loss     | 1.24e+04  |\n",
      "|    ent_coef        | 8.67      |\n",
      "|    ent_coef_loss   | -0.0405   |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 80502     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.7      |\n",
      "|    ep_rew_mean     | -3.58e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 48000     |\n",
      "|    fps             | 744       |\n",
      "|    time_elapsed    | 3522      |\n",
      "|    total_timesteps | 2621888   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.44e+03  |\n",
      "|    critic_loss     | 1.27e+04  |\n",
      "|    ent_coef        | 8.68      |\n",
      "|    ent_coef_loss   | 0.261     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 81930     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48.6      |\n",
      "|    ep_rew_mean     | -3.57e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 49000     |\n",
      "|    fps             | 743       |\n",
      "|    time_elapsed    | 3590      |\n",
      "|    total_timesteps | 2669792   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.41e+03  |\n",
      "|    critic_loss     | 1.1e+04   |\n",
      "|    ent_coef        | 8.67      |\n",
      "|    ent_coef_loss   | 0.058     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 83427     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48.7      |\n",
      "|    ep_rew_mean     | -3.79e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 50000     |\n",
      "|    fps             | 742       |\n",
      "|    time_elapsed    | 3657      |\n",
      "|    total_timesteps | 2716032   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.31e+03  |\n",
      "|    critic_loss     | 7.02e+03  |\n",
      "|    ent_coef        | 8.7       |\n",
      "|    ent_coef_loss   | 0.167     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 84872     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.3      |\n",
      "|    ep_rew_mean     | -3.29e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 51000     |\n",
      "|    fps             | 741       |\n",
      "|    time_elapsed    | 3723      |\n",
      "|    total_timesteps | 2762656   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.36e+03  |\n",
      "|    critic_loss     | 7.42e+03  |\n",
      "|    ent_coef        | 8.95      |\n",
      "|    ent_coef_loss   | -0.296    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 86329     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.5      |\n",
      "|    ep_rew_mean     | -3.42e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 52000     |\n",
      "|    fps             | 741       |\n",
      "|    time_elapsed    | 3789      |\n",
      "|    total_timesteps | 2808832   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.25e+03  |\n",
      "|    critic_loss     | 1.67e+04  |\n",
      "|    ent_coef        | 8.86      |\n",
      "|    ent_coef_loss   | 0.165     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 87772     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 44        |\n",
      "|    ep_rew_mean     | -3.13e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 53000     |\n",
      "|    fps             | 740       |\n",
      "|    time_elapsed    | 3854      |\n",
      "|    total_timesteps | 2854880   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.15e+03  |\n",
      "|    critic_loss     | 5.36e+03  |\n",
      "|    ent_coef        | 8.95      |\n",
      "|    ent_coef_loss   | -0.136    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 89211     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 44.4      |\n",
      "|    ep_rew_mean     | -3.17e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 54000     |\n",
      "|    fps             | 740       |\n",
      "|    time_elapsed    | 3920      |\n",
      "|    total_timesteps | 2901568   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.16e+03  |\n",
      "|    critic_loss     | 7.72e+03  |\n",
      "|    ent_coef        | 9.04      |\n",
      "|    ent_coef_loss   | -0.0381   |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 90670     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.7      |\n",
      "|    ep_rew_mean     | -3.34e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 55000     |\n",
      "|    fps             | 739       |\n",
      "|    time_elapsed    | 3988      |\n",
      "|    total_timesteps | 2948864   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.35e+03  |\n",
      "|    critic_loss     | 9.81e+03  |\n",
      "|    ent_coef        | 9.02      |\n",
      "|    ent_coef_loss   | -0.368    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 92148     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.1      |\n",
      "|    ep_rew_mean     | -3.21e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 56000     |\n",
      "|    fps             | 738       |\n",
      "|    time_elapsed    | 4056      |\n",
      "|    total_timesteps | 2995872   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.13e+03  |\n",
      "|    critic_loss     | 4.82e+03  |\n",
      "|    ent_coef        | 9.07      |\n",
      "|    ent_coef_loss   | 0.242     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 93617     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 43.2      |\n",
      "|    ep_rew_mean     | -2.97e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 57000     |\n",
      "|    fps             | 737       |\n",
      "|    time_elapsed    | 4125      |\n",
      "|    total_timesteps | 3043616   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.25e+03  |\n",
      "|    critic_loss     | 6.24e+03  |\n",
      "|    ent_coef        | 9.15      |\n",
      "|    ent_coef_loss   | 0.234     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 95109     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48.4      |\n",
      "|    ep_rew_mean     | -3.23e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 58000     |\n",
      "|    fps             | 737       |\n",
      "|    time_elapsed    | 4190      |\n",
      "|    total_timesteps | 3089664   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.24e+03  |\n",
      "|    critic_loss     | 3.95e+03  |\n",
      "|    ent_coef        | 9.1       |\n",
      "|    ent_coef_loss   | -0.295    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 96548     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 46.6      |\n",
      "|    ep_rew_mean     | -3.11e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 59000     |\n",
      "|    fps             | 736       |\n",
      "|    time_elapsed    | 4255      |\n",
      "|    total_timesteps | 3135872   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 3.97e+03  |\n",
      "|    critic_loss     | 3.9e+03   |\n",
      "|    ent_coef        | 9.14      |\n",
      "|    ent_coef_loss   | -0.144    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 97992     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 48.5      |\n",
      "|    ep_rew_mean     | -3.25e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 60000     |\n",
      "|    fps             | 736       |\n",
      "|    time_elapsed    | 4318      |\n",
      "|    total_timesteps | 3182624   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.23e+03  |\n",
      "|    critic_loss     | 3.23e+03  |\n",
      "|    ent_coef        | 9.16      |\n",
      "|    ent_coef_loss   | -0.129    |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 99453     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 47.8      |\n",
      "|    ep_rew_mean     | -3.22e+03 |\n",
      "| time/              |           |\n",
      "|    episodes        | 61000     |\n",
      "|    fps             | 736       |\n",
      "|    time_elapsed    | 4383      |\n",
      "|    total_timesteps | 3229600   |\n",
      "| train/             |           |\n",
      "|    actor_loss      | 4.02e+03  |\n",
      "|    critic_loss     | 4.13e+03  |\n",
      "|    ent_coef        | 9.05      |\n",
      "|    ent_coef_loss   | 0.332     |\n",
      "|    learning_rate   | 0.0003    |\n",
      "|    n_updates       | 100921    |\n",
      "----------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Sergei\\git\\walking-robot-neural-control\\2022-robotics-sim-state\\stable_baselines.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Sergei/git/walking-robot-neural-control/2022-robotics-sim-state/stable_baselines.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mlearn(total_timesteps\u001b[39m=\u001b[39;49m\u001b[39m5e7\u001b[39;49m, log_interval\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Sergei/git/walking-robot-neural-control/2022-robotics-sim-state/stable_baselines.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mg1\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\stable_baselines3\\sac\\sac.py:298\u001b[0m, in \u001b[0;36mSAC.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearn\u001b[39m(\n\u001b[0;32m    286\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    287\u001b[0m     total_timesteps: \u001b[39mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    295\u001b[0m     reset_num_timesteps: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    296\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m OffPolicyAlgorithm:\n\u001b[1;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mlearn(\n\u001b[0;32m    299\u001b[0m         total_timesteps\u001b[39m=\u001b[39;49mtotal_timesteps,\n\u001b[0;32m    300\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    301\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    302\u001b[0m         eval_env\u001b[39m=\u001b[39;49meval_env,\n\u001b[0;32m    303\u001b[0m         eval_freq\u001b[39m=\u001b[39;49meval_freq,\n\u001b[0;32m    304\u001b[0m         n_eval_episodes\u001b[39m=\u001b[39;49mn_eval_episodes,\n\u001b[0;32m    305\u001b[0m         tb_log_name\u001b[39m=\u001b[39;49mtb_log_name,\n\u001b[0;32m    306\u001b[0m         eval_log_path\u001b[39m=\u001b[39;49meval_log_path,\n\u001b[0;32m    307\u001b[0m         reset_num_timesteps\u001b[39m=\u001b[39;49mreset_num_timesteps,\n\u001b[0;32m    308\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:346\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[0;32m    343\u001b[0m callback\u001b[39m.\u001b[39mon_training_start(\u001b[39mlocals\u001b[39m(), \u001b[39mglobals\u001b[39m())\n\u001b[0;32m    345\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 346\u001b[0m     rollout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollect_rollouts(\n\u001b[0;32m    347\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv,\n\u001b[0;32m    348\u001b[0m         train_freq\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_freq,\n\u001b[0;32m    349\u001b[0m         action_noise\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_noise,\n\u001b[0;32m    350\u001b[0m         callback\u001b[39m=\u001b[39;49mcallback,\n\u001b[0;32m    351\u001b[0m         learning_starts\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlearning_starts,\n\u001b[0;32m    352\u001b[0m         replay_buffer\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreplay_buffer,\n\u001b[0;32m    353\u001b[0m         log_interval\u001b[39m=\u001b[39;49mlog_interval,\n\u001b[0;32m    354\u001b[0m     )\n\u001b[0;32m    356\u001b[0m     \u001b[39mif\u001b[39;00m rollout\u001b[39m.\u001b[39mcontinue_training \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    357\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\stable_baselines3\\common\\off_policy_algorithm.py:579\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[0;32m    576\u001b[0m actions, buffer_actions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[39m.\u001b[39mnum_envs)\n\u001b[0;32m    578\u001b[0m \u001b[39m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m new_obs, rewards, dones, infos \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39;49mstep(actions)\n\u001b[0;32m    581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_timesteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mnum_envs\n\u001b[0;32m    582\u001b[0m num_collected_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:162\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \n\u001b[0;32m    158\u001b[0m \u001b[39m:param actions: the action\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 162\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep_wait()\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:43\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep_wait\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     42\u001b[0m     \u001b[39mfor\u001b[39;00m env_idx \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_envs):\n\u001b[1;32m---> 43\u001b[0m         obs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_rews[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menvs[env_idx]\u001b[39m.\u001b[39;49mstep(\n\u001b[0;32m     44\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactions[env_idx]\n\u001b[0;32m     45\u001b[0m         )\n\u001b[0;32m     46\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_dones[env_idx]:\n\u001b[0;32m     47\u001b[0m             \u001b[39m# save final observation where user can get it, then reset\u001b[39;00m\n\u001b[0;32m     48\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuf_infos[env_idx][\u001b[39m\"\u001b[39m\u001b[39mterminal_observation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m obs\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:90\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneeds_reset:\n\u001b[0;32m     89\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTried to step environment that needs reset\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 90\u001b[0m observation, reward, done, info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrewards\u001b[39m.\u001b[39mappend(reward)\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m done:\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\wrappers\\time_limit.py:60\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     49\u001b[0m     \u001b[39m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \n\u001b[0;32m     51\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39m        \"TimeLimit.truncated\"=False if the environment terminated\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     observation, reward, terminated, truncated, info \u001b[39m=\u001b[39m step_api_compatibility(\n\u001b[1;32m---> 60\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action),\n\u001b[0;32m     61\u001b[0m         \u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elapsed_steps \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m ResetNeeded(\u001b[39m\"\u001b[39m\u001b[39mCannot call env.step() before calling env.reset()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\wrappers\\step_api_compatibility.py:52\u001b[0m, in \u001b[0;36mStepAPICompatibility.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m     44\u001b[0m     \u001b[39m\"\"\"Steps through the environment, returning 5 or 4 items depending on `new_step_api`.\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m        (observation, reward, terminated, truncated, info) or (observation, reward, done, info)\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     step_returns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnew_step_api:\n\u001b[0;32m     54\u001b[0m         \u001b[39mreturn\u001b[39;00m step_to_new_api(step_returns)\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m env_step_passive_checker(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menv\u001b[39m.\u001b[39;49mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\git\\walking-robot-neural-control\\2022-robotics-sim-state\\environments\\g1.py:116\u001b[0m, in \u001b[0;36mG1DistanceEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, action):\n\u001b[0;32m    114\u001b[0m     xy_position_before \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_body_com(\u001b[39m\"\u001b[39m\u001b[39mtrunk\u001b[39m\u001b[39m\"\u001b[39m)[:\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m--> 116\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdo_simulation(action, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframe_skip)\n\u001b[0;32m    117\u001b[0m     xy_position_after \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_body_com(\u001b[39m\"\u001b[39m\u001b[39mtrunk\u001b[39m\u001b[39m\"\u001b[39m)[:\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    119\u001b[0m     xy_velocity \u001b[39m=\u001b[39m (xy_position_after \u001b[39m-\u001b[39m xy_position_before) \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdt\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\envs\\mujoco\\mujoco_env.py:177\u001b[0m, in \u001b[0;36mBaseMujocoEnv.do_simulation\u001b[1;34m(self, ctrl, n_frames)\u001b[0m\n\u001b[0;32m    171\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39mStep the simulation n number of frames and applying a control action.\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m# Check control input is contained in the action space\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39m# if np.array(ctrl).shape != self.action_space.shape:\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[39m# raise ValueError(\"Action dimension mismatch\")\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step_mujoco_simulation(ctrl, n_frames)\n",
      "File \u001b[1;32mc:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\envs\\mujoco\\mujoco_env.py:390\u001b[0m, in \u001b[0;36mMujocoEnv._step_mujoco_simulation\u001b[1;34m(self, ctrl, n_frames)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_step_mujoco_simulation\u001b[39m(\u001b[39mself\u001b[39m, ctrl, n_frames):\n\u001b[0;32m    388\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mctrl[:] \u001b[39m=\u001b[39m ctrl\n\u001b[1;32m--> 390\u001b[0m     mujoco\u001b[39m.\u001b[39;49mmj_step(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, nstep\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mframe_skip)\n\u001b[0;32m    392\u001b[0m     \u001b[39m# As of MuJoCo 2.0, force-related quantities like cacc are not computed\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     \u001b[39m# unless there's a force sensor in the model.\u001b[39;00m\n\u001b[0;32m    394\u001b[0m     \u001b[39m# See https://github.com/openai/gym/issues/1541\u001b[39;00m\n\u001b[0;32m    395\u001b[0m     mujoco\u001b[39m.\u001b[39mmj_rnePostConstraint(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=5e7, log_interval=1000)\n",
    "model.save(\"g1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"G1Dist-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\core.py:57: DeprecationWarning: \u001b[33mWARN: You are calling render method, but you didn't specified the argument render_mode at environment initialization. To maintain backward compatibility, the environment will render in human mode.\n",
      "If you want to render in human mode, initialize the environment in this way: gym.make('EnvName', render_mode='human') and don't call the render method.\n",
      "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
      "  deprecation(\n",
      "c:\\Users\\Sergei\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\glfw\\__init__.py:906: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if np.all(done):\n",
    "      obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "74d63dd06fb5b9584c5a99e0f23a7a9506726cecc90dfceeb064a9b990e8da94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
